{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24393200-92f2-40e3-918c-fc3a72cb0a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90724417-8a0a-42df-9f0f-4653a9a06d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: long (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: long (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: long (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- Airport_fee: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw_data = spark.read.parquet('data/raw/yellow/2024/10/*')\n",
    "\n",
    "df_raw_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7cca2cb9-e65f-4b85-b4d0-4d2b67f83ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('data/raw/yellow/2024/10/*') \\\n",
    "    .drop('Airport_fee') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "380e9d61-4e1f-4575-886d-9ee3b82d9743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: timestamp (nullable = true)\n",
      " |-- tpep_dropoff_datetime: timestamp (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- RatecodeID: integer (nullable = true)\n",
      " |-- store_and_fwd_flag: string (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- payment_type: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- mta_tax: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- tolls_amount: double (nullable = true)\n",
      " |-- improvement_surcharge: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_raw_data_casted = df_raw_data \\\n",
    "    .withColumn(\"VendorID\", df_raw_data[\"VendorID\"].cast(types.IntegerType())) \\\n",
    "    .withColumn(\"tpep_pickup_datetime\", df_raw_data[\"tpep_pickup_datetime\"].cast(types.TimestampType())) \\\n",
    "    .withColumn(\"tpep_dropoff_datetime\", df_raw_data[\"tpep_dropoff_datetime\"].cast(types.TimestampType())) \\\n",
    "    .withColumn(\"passenger_count\", df_raw_data[\"passenger_count\"].cast(types.IntegerType())) \\\n",
    "    .withColumn(\"trip_distance\", df_raw_data[\"trip_distance\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"RatecodeID\", df_raw_data[\"RatecodeID\"].cast(types.IntegerType())) \\\n",
    "    .withColumn(\"store_and_fwd_flag\", df_raw_data[\"store_and_fwd_flag\"].cast(types.StringType())) \\\n",
    "    .withColumn(\"PULocationID\", df_raw_data[\"PULocationID\"].cast(types.IntegerType())) \\\n",
    "    .withColumn(\"DOLocationID\", df_raw_data[\"DOLocationID\"].cast(types.IntegerType())) \\\n",
    "    .withColumn(\"payment_type\", df_raw_data[\"payment_type\"].cast(types.IntegerType())) \\\n",
    "    .withColumn(\"fare_amount\", df_raw_data[\"fare_amount\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"extra\", df_raw_data[\"extra\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"mta_tax\", df_raw_data[\"mta_tax\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"tip_amount\", df_raw_data[\"tip_amount\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"tolls_amount\", df_raw_data[\"tolls_amount\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"improvement_surcharge\", df_raw_data[\"improvement_surcharge\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"total_amount\", df_raw_data[\"total_amount\"].cast(types.DoubleType())) \\\n",
    "    .withColumn(\"congestion_surcharge\", df_raw_data[\"congestion_surcharge\"].cast(types.DoubleType()))\n",
    "\n",
    "df_raw_data_casted.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5ab404c-48bc-425a-9e32-4025cdce82e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_data_casted \\\n",
    "    .repartition(4) \\\n",
    "    .write.parquet('data/pq/yellow/2024/10/', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "29be91e2-05bc-4707-bcc1-18737464b6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Data Engineering\\software\\spark-3.3.2-bin-hadoop3\\python\\pyspark\\sql\\dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_pq = spark.read.parquet ('data/pq/yellow/2024/10/*')\n",
    "\n",
    "df_pq = df_pq \\\n",
    "    .withColumnRenamed('tpep_pickup_datetime', 'pickup_datetime') \\\n",
    "    .withColumnRenamed('tpep_dropoff_datetime', 'dropoff_datetime')\n",
    "\n",
    "df_pq.registerTempTable('yellow_tripdata_1024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2c29f3be-b307-466c-a3a6-7cc12db11168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+\n",
      "|num_trips|      date|\n",
      "+---------+----------+\n",
      "|   128097|2024-10-15|\n",
      "+---------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pq = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    COUNT (*) AS num_trips,\n",
    "    CAST(pickup_datetime AS DATE) AS date\n",
    "FROM yellow_tripdata_1024\n",
    "WHERE pickup_datetime >= '2024-10-15'\n",
    "    AND pickup_datetime < '2024-10-16'\n",
    "GROUP BY date\n",
    "\"\"\")\n",
    "\n",
    "df_pq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94bbbf9c-cdd7-46ea-b284-e1c8c007d9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---------------+\n",
      "|    pickup_datetime|   dropoff_datetime|time_diff_hours|\n",
      "+-------------------+-------------------+---------------+\n",
      "|2024-10-16 14:03:49|2024-10-23 08:40:53|         162.62|\n",
      "|2024-10-03 19:47:25|2024-10-09 19:06:55|         143.33|\n",
      "|2024-10-22 17:00:55|2024-10-28 10:46:33|         137.76|\n",
      "+-------------------+-------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pq = spark.sql(\"\"\"\n",
    "SELECT\n",
    "   pickup_datetime,\n",
    "   dropoff_datetime,\n",
    "   ROUND ((UNIX_TIMESTAMP(dropoff_datetime) - UNIX_TIMESTAMP(pickup_datetime)) / 3600, 2) AS time_diff_hours\n",
    "FROM yellow_tripdata_1024\n",
    "ORDER BY time_diff_hours DESC\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "\n",
    "df_pq.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d07847e-793f-4f97-a722-f60030ce370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones_csv = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('taxi_zone_lookup.csv')\n",
    "\n",
    "df_zones_csv.write.parquet('data/pq/zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "81e85b0e-a358-4c3c-8b1c-25b4254ed87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet('data/pq/zones/*')\n",
    "\n",
    "df_pq_table = spark.read.parquet('data/pq/yellow/2024/10/*')\n",
    "\n",
    "df_join = df_pq_table.join(df_zones, df_pq_table.PULocationID == df_zones.LocationID)\n",
    "\n",
    "df_join.registerTempTable('trips_zones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "2acbdbec-84ce-4083-bdf0-4aea094939e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------------------------------------------+\n",
      "|num_trips|PULocationID|Zone                                         |\n",
      "+---------+------------+---------------------------------------------+\n",
      "|1        |105         |Governor's Island/Ellis Island/Liberty Island|\n",
      "|2        |5           |Arden Heights                                |\n",
      "|2        |199         |Rikers Island                                |\n",
      "+---------+------------+---------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_join = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    COUNT (*) AS num_trips,\n",
    "    PULocationID,\n",
    "    Zone\n",
    "FROM trips_zones\n",
    "GROUP BY 2,3\n",
    "ORDER BY 1\n",
    "LIMIT 3\n",
    "\"\"\")\n",
    "df_join.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d241aa-9095-455b-9116-49a02e6f1c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
